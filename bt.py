# -*- coding: utf-8 -*-
"""BT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NcgOv6SLXoOiTSnJNqI1eZKS-4VGLejV
"""

import cv2
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os
import argparse
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, f1_score
import joblib
import torch
import torch.nn as nn
from torchvision.transforms import Resize, ToTensor, Compose, Normalize, transforms
from torchvision.models import resnet34, resnet18
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import numpy as np
import os

data = pd.read_csv("/content/gdrive/MyDrive/NCKH/class.csv")

data.head()

images = data.Image
classes = data.Class
image_label_dict = data.set_index('Image')['Class'].to_dict()
print(image_label_dict)

Y = []
list_filename = image_label_dict.keys()
for filename in list_filename:
  Y.append(image_label_dict[filename])

import cv2
import numpy as np
from sklearn.decomposition import NMF
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from google.colab.patches import cv2_imshow


def apply_thresholding(image, threshold_value):
    _, thresholded = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)
    return thresholded

import numpy as np
import cv2
from os import listdir
from collections import defaultdict
from sklearn.utils import resample

dir_list = '/content/gdrive/MyDrive/NCKH/Crop/'
image_paths = {}
for filename in listdir(dir_list):
    if filename.endswith('.jpg'):
        label = image_label_dict.get(filename.split('.')[0], None)
        if label is not None:
            if label not in image_paths:
                image_paths[label] = []
            image_paths[label].append(dir_list + filename)

# Quy định số lượng mẫu mong muốn trong mỗi lớp
desired_samples = 750

X_balanced = []
Y_balanced = []
X = []
Y = []

# Lấy mẫu ngẫu nhiên từ mỗi lớp với số lượng mẫu mong muốn
for label, paths in image_paths.items():
    sampled_paths = resample(paths, replace=False, n_samples=desired_samples)
    for path in paths:
        image = cv2.imread(path)
        mri_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        thresholded_image = apply_thresholding(mri_image, threshold_value=50)
        image = cv2.bitwise_and(mri_image, mri_image, mask=thresholded_image)
        if image is not None:
            image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)
            # cv2_imshow(image)
            image = image / 255.0
            X_balanced.append(image)
            Y_balanced.append(label)

X = np.array(X_balanced)
Y = np.array(Y_balanced)

from google.colab.patches import cv2_imshow
# image_paths[label][0]
image = cv2.imread(image_paths[label][100])
mri_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresholded_image = apply_thresholding(mri_image, threshold_value=50)
image1 = cv2.bitwise_and(image, image, mask=thresholded_image)
image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
cv2_imshow(image1)
cv2_imshow(image)
cv2_imshow(thresholded_image)
cv2_imshow(mri_image)
image1 = image1.reshape(-1,)
print(image.shape, image1.shape, mri_image.shape)
print(image1)
image1 = image1 / 255.0
unique_values, counts = np.unique(image1, return_counts=True)

# In kết quả
for value, count in zip(unique_values, counts):
    print(f'Giá trị {value} xuất hiện {count} lần')

X = np.array(X)
Y = np.array(Y)

unique_values, counts = np.unique(X[0], return_counts=True)

# In kết quả
for value, count in zip(unique_values, counts):
    print(f'Giá trị {value} xuất hiện {count} lần')

# Commented out IPython magic to ensure Python compatibility.
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.utils import shuffle
import cv2
import imutils
import numpy as np
import matplotlib.pyplot as plt
import time
from os import listdir

# %matplotlib inline

# n = 500
# for label in [0,1]:
#   images = X[np.argwhere(Y == label)]
#   n_images = images[:n]
#   columns_n = 10
#   rows_n = int(n/ columns_n)
#   plt.figure(figsize=(20, 10))
#   for image in n_images:
#     plt.subplot(rows_n, columns_n, i)
#     plt.imshow(image[0])
#     plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)
#   label_to_str = lambda label: "Yes" if label == 1 else "No"
#   plt.suptitle(f"Brain Tumor: {label_to_str(label)}")
#   plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test_val, Y_train, Y_test_val = train_test_split(X, Y, test_size=0.4)
X_test, X_val, Y_test, Y_val = train_test_split(X_test_val, Y_test_val, test_size=0.5)


print ("number of training examples = " + str(X_train.shape[0]))
print ("number of development examples = " + str(X_val.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))
print ("X_train shape: " + str(X_train.shape))
print ("Y_train shape: " + str(Y_train.shape))
print ("X_val (dev) shape: " + str(X_val.shape))
print ("Y_val (dev) shape: " + str(Y_val.shape))
print ("X_test shape: " + str(X_test.shape))
print ("Y_test shape: " + str(Y_test.shape))

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint
def build_model(input_shape):
    """
    Arugments:
        input_shape: A tuple representing the shape of the input of the model. shape=(image_width, image_height, #_channels)
    Returns:
        model: A Model object.
    """
    # Define the input placeholder as a tensor with shape input_shape.
    X_input = Input(input_shape) # shape=(?, 240, 240, 3)

    # Zero-Padding: pads the border of X_input with zeroes
    # X = ZeroPadding2D((2, 2))(X_input) # shape=(?, 244, 244, 3)
    X = X_input

    # CONV -> BN -> RELU Block applied to X
    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)
    X = BatchNormalization(axis = 3, name = 'bn0')(X)
    X = Activation('relu')(X) # shape=(?, 238, 238, 32)

    # MAXPOOL
    X = MaxPooling2D((4, 4), name='max_pool0')(X) # shape=(?, 59, 59, 32)

    # MAXPOOL
    X = MaxPooling2D((4, 4), name='max_pool1')(X) # shape=(?, 14, 14, 32)

    # FLATTEN X
    X = Flatten()(X) # shape=(?, 6272)
    # FULLYCONNECTED
    X = Dense(1, activation='sigmoid', name='fc')(X)  # Dense layer với 1 unit, sử dụng activation sigmoid để phân loại

    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.
    model = Model(inputs = X_input, outputs = X, name='BrainDetectionModel')

    return model
IMG_SHAPE = (224, 224, 1)
model = build_model(IMG_SHAPE)
model.summary()

# Nicely formatted time string
def hms_string(sec_elapsed):
    h = int(sec_elapsed / (60 * 60))
    m = int((sec_elapsed % (60 * 60)) / 60)
    s = sec_elapsed % 60
    return f"{h}:{m}:{round(s,1)}"
def compute_f1_score(y_true, prob):
    # convert the vector of probabilities to a target vector
    y_pred = np.where(prob > 0.5, 1, 0)

    score = f1_score(y_true, y_pred)

    return score

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, BatchNormalization, Activation, Dropout
from tensorflow.keras.models import Model

def create_cnn_model(input_shape, num_filters):
    inputs = Input(shape=input_shape)
    x = Conv2D(num_filters, (3, 3), activation='relu')(inputs)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(num_filters * 2, (3, 3), activation='relu')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Flatten()(x)
    x = Dense(64, activation='relu')(x)
    outputs = Dense(1, activation='sigmoid')(x)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

model1 = create_cnn_model((224, 224, 1), 32)
model2 = create_cnn_model((224, 224, 1), 64)
model3 = create_cnn_model((224, 224, 1), 48)

model1.fit(X_train, Y_train, epochs=8, batch_size=32, validation_split=0.2)
model2.fit(X_train, Y_train, epochs=8, batch_size=32, validation_split=0.2)
model3.fit(X_train, Y_train, epochs=8, batch_size=32, validation_split=0.2)

y_pred1 = model3.predict(X_test)
y_pred2 = (y_pred1 > 0.2).astype(int)
f1 = f1_score(Y_test, y_pred2)
print(f1)
print(f'F1 Score: {f1}')
for i, j in zip(y_pred1, Y_test):
  print(i, j)

from sklearn.metrics import classification_report
print(classification_report(Y_test, y_pred2))

np.unique(Y_train, return_counts=True)

from tensorflow.keras.layers import concatenate
from tensorflow.keras.models import Model

def create_ensemble_model(models, input_shape):
    # Create a list to hold all the model outputs
    outputs = []
    # Create a common input layer
    common_input = Input(shape=input_shape)

    # Loop through all models and connect the common input to each
    for i, model in enumerate(models):
        # We assume that each model has its layers cloned with a new name to avoid name clashes
        for layer in model.layers[1:]:  # skip the input layer of each model
            layer._name = f'model_{i}_{layer.name}'

        # Connect the model to the common input and store the output
        outputs.append(model(common_input))

    # Concatenate all outputs
    if len(outputs) > 1:
        combined_output = concatenate(outputs)
    else:
        combined_output = outputs[0]

    # Add a dense layer to learn from all combined outputs
    y = Dense(64, activation='relu')(combined_output)
    y = Dense(1, activation='sigmoid')(y)

    # Create the final model
    model = Model(inputs=common_input, outputs=y)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Assuming model1, model2, model3 are already created and compiled
ensemble_model = create_ensemble_model([model1, model2, model3], (224, 224, 1))
ensemble_model.summary()

evaluation = ensemble_model.evaluate(X_val, Y_val)
print(f"Loss: {evaluation[0]}, Accuracy: {evaluation[1]}")

# Train the ensemble model
ensemble_model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_val, Y_val))

# Evaluate the model
performance = ensemble_model.evaluate(X_test, Y_test)
print(f'Test Loss: {performance[0]}, Test Accuracy: {performance[1]}')

# Predict and calculate F1 score
y_pred = ensemble_model.predict(X_test)
for i, j in zip(y_pred, Y_test):
  print(i, j)
y_pred = (y_pred>0.5 ).astype(int)
for i, j in zip(y_pred, Y_test):
  print(i, j)
f1 = f1_score(Y_test, y_pred)
print(f'F1 Score: {f1}')

from sklearn.metrics import classification_report
print(classification_report(Y_test, y_pred))

# def plot_metrics(history):

#     train_loss = history['loss']
#     val_loss = history['val_loss']
#     train_acc = history['accuracy']
#     val_acc = history['val_accuracy']

#     # Loss
#     plt.figure()
#     plt.plot(train_loss, label='Training Loss')
#     plt.plot(val_loss, label='Validation Loss')
#     plt.title('Loss')
#     plt.legend()
#     plt.show()

#     # Accuracy
#     plt.figure()
#     plt.plot(train_acc, label='Training Accuracy')
#     plt.plot(val_acc, label='Validation Accuracy')
#     plt.title('Accuracy')
#     plt.legend()
#     plt.show()

def plot_metrics(history):
    # Adjust the keys according to what is printed by the `print` statement above
    train_loss = history.get('loss', [])
    val_loss = history.get('val_loss', [])
    train_acc = history.get('accuracy', history.get('acc', []))
    val_acc = history.get('val_accuracy', history.get('val_acc', []))

    if not train_loss or not train_acc:
        print("Loss or accuracy metrics are missing in history.")
        return

    # Loss
    plt.figure()
    plt.plot(train_loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.title('Loss')
    plt.legend()
    plt.show()

    # Accuracy
    plt.figure()
    plt.plot(train_acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.title('Accuracy')
    plt.legend()
    plt.show()

# Gọi hàm với đối số là ensemble_model.history.history
plot_metrics(ensemble_model.history.history)

"""#Resnet18"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def preprocess_image(image_path):
    image = Image.open(image_path).convert('RGB')
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    image = transform(image)
    image = image.unsqueeze(0)
    return image.to(device)

def extract_features(image, model):
    with torch.no_grad():
        feature = model(image).squeeze().cpu().numpy()
    return feature

def extract_features_from_image(image_path, model):
    image = preprocess_image(image_path)
    feature = extract_features(image, model)
    return feature

resnet18_model = resnet18(pretrained=True)
resnet18_model = nn.Sequential(*list(resnet18_model.children())[:-1])
resnet18_model = resnet18_model.to(device)
resnet18_model.eval()

features_resnet18 = []
for image_path in tqdm(image_paths):
  features_resnet18.append(extract_features_from_image(image_path, resnet18_model))